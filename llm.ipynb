{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a402deb-6364-445b-b096-104f5db426de",
   "metadata": {},
   "source": [
    "# LLM inference\n",
    "\n",
    "Loads GPT2 weights of choice or saved weights and shows how to run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fbb54484-983f-451b-83c3-81f1f1cde261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "31f5d865-424f-419a-87aa-aed714dcbfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chapter04 import generate_text_simple\n",
    "from chapter05 import text_to_token_ids, token_ids_to_text, GPTModel, load_weights_into_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bb407e04-b604-4058-972d-50203c2be936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch loaded. version 2.9.1\n",
      "MPS available: True\n",
      "tiktoken version: 0.12.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "print(f'Torch loaded. version {torch.__version__}')\n",
    "print(f'MPS available: {torch.backends.mps.is_available()}')\n",
    "print(\"tiktoken version:\", version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15385f5-8b40-420c-a93f-26b4b4ef5d3a",
   "metadata": {},
   "source": [
    "## model config\n",
    "sizes available (\"124M\", \"355M\", \"774M\", \"1558M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "60cb71b6-864e-4f5e-9784-443f209802a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12, \"model_name\": \"124M\"},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16, \"model_name\": \"355M\"},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20, \"model_name\": \"774M\"},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25, \"model_name\": \"1558M\"},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6a47d13a-7aaa-45f2-b0e3-171ba8582149",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "40315963-4317-46de-b996-50f3106b5bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2-xl (1558M)\"\n",
    "GPT_CONFIG.update(model_configs[model_name])\n",
    "GPT_CONFIG.update({\"context_length\": 1024}) # woo bigger context\n",
    "GPT_CONFIG.update({\"qkv_bias\": True}) # gpt2 uses bias on the qkv weight parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5d7a81a0-19b3-4dac-8181-704e7dfee573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt = GPTModel(GPT_CONFIG)\n",
    "gpt.eval()\n",
    "True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c765a3e4-5cbe-4e04-a026-c38cc7c86fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## torchinfo is a nice package to show more model information than pytorch print gives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6d90af8d-2133-465a-a8de-248ce7350b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "GPTModel                                      [1, 1024, 50257]          --\n",
       "├─Embedding: 1-1                              [1, 1024, 1600]           80,411,200\n",
       "├─Embedding: 1-2                              [1024, 1600]              1,638,400\n",
       "├─Dropout: 1-3                                [1, 1024, 1600]           --\n",
       "├─Sequential: 1-4                             [1, 1024, 1600]           --\n",
       "│    └─TransformerBlock: 2-1                  [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-1                    [1, 1024, 1600]           3,200\n",
       "│    │    └─MultiHeadAttention: 3-2           [1, 1024, 1600]           10,246,400\n",
       "│    │    └─Dropout: 3-3                      [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-4                    [1, 1024, 1600]           3,200\n",
       "│    │    └─FeedForward: 3-5                  [1, 1024, 1600]           20,488,000\n",
       "│    │    └─Dropout: 3-6                      [1, 1024, 1600]           --\n",
       "│    └─TransformerBlock: 2-2                  [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-7                    [1, 1024, 1600]           3,200\n",
       "│    │    └─MultiHeadAttention: 3-8           [1, 1024, 1600]           10,246,400\n",
       "│    │    └─Dropout: 3-9                      [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-10                   [1, 1024, 1600]           3,200\n",
       "│    │    └─FeedForward: 3-11                 [1, 1024, 1600]           20,488,000\n",
       "│    │    └─Dropout: 3-12                     [1, 1024, 1600]           --\n",
       "│    └─TransformerBlock: 2-3                  [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-13                   [1, 1024, 1600]           3,200\n",
       "│    │    └─MultiHeadAttention: 3-14          [1, 1024, 1600]           10,246,400\n",
       "│    │    └─Dropout: 3-15                     [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-16                   [1, 1024, 1600]           3,200\n",
       "│    │    └─FeedForward: 3-17                 [1, 1024, 1600]           20,488,000\n",
       "│    │    └─Dropout: 3-18                     [1, 1024, 1600]           --\n",
       "│    └─TransformerBlock: 2-4                  [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-19                   [1, 1024, 1600]           3,200\n",
       "│    │    └─MultiHeadAttention: 3-20          [1, 1024, 1600]           10,246,400\n",
       "│    │    └─Dropout: 3-21                     [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-22                   [1, 1024, 1600]           3,200\n",
       "│    │    └─FeedForward: 3-23                 [1, 1024, 1600]           20,488,000\n",
       "│    │    └─Dropout: 3-24                     [1, 1024, 1600]           --\n",
       "│    └─TransformerBlock: 2-5                  [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-25                   [1, 1024, 1600]           3,200\n",
       "│    │    └─MultiHeadAttention: 3-26          [1, 1024, 1600]           10,246,400\n",
       "│    │    └─Dropout: 3-27                     [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-28                   [1, 1024, 1600]           3,200\n",
       "│    │    └─FeedForward: 3-29                 [1, 1024, 1600]           20,488,000\n",
       "│    │    └─Dropout: 3-30                     [1, 1024, 1600]           --\n",
       "│    └─TransformerBlock: 2-6                  [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-31                   [1, 1024, 1600]           3,200\n",
       "│    │    └─MultiHeadAttention: 3-32          [1, 1024, 1600]           10,246,400\n",
       "│    │    └─Dropout: 3-33                     [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-34                   [1, 1024, 1600]           3,200\n",
       "│    │    └─FeedForward: 3-35                 [1, 1024, 1600]           20,488,000\n",
       "│    │    └─Dropout: 3-36                     [1, 1024, 1600]           --\n",
       "│    └─TransformerBlock: 2-7                  [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-37                   [1, 1024, 1600]           3,200\n",
       "│    │    └─MultiHeadAttention: 3-38          [1, 1024, 1600]           10,246,400\n",
       "│    │    └─Dropout: 3-39                     [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-40                   [1, 1024, 1600]           3,200\n",
       "│    │    └─FeedForward: 3-41                 [1, 1024, 1600]           20,488,000\n",
       "│    │    └─Dropout: 3-42                     [1, 1024, 1600]           --\n",
       "│    └─TransformerBlock: 2-8                  [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-43                   [1, 1024, 1600]           3,200\n",
       "│    │    └─MultiHeadAttention: 3-44          [1, 1024, 1600]           10,246,400\n",
       "│    │    └─Dropout: 3-45                     [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-46                   [1, 1024, 1600]           3,200\n",
       "│    │    └─FeedForward: 3-47                 [1, 1024, 1600]           20,488,000\n",
       "│    │    └─Dropout: 3-48                     [1, 1024, 1600]           --\n",
       "│    └─TransformerBlock: 2-9                  [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-49                   [1, 1024, 1600]           3,200\n",
       "│    │    └─MultiHeadAttention: 3-50          [1, 1024, 1600]           10,246,400\n",
       "│    │    └─Dropout: 3-51                     [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-52                   [1, 1024, 1600]           3,200\n",
       "│    │    └─FeedForward: 3-53                 [1, 1024, 1600]           20,488,000\n",
       "│    │    └─Dropout: 3-54                     [1, 1024, 1600]           --\n",
       "│    └─TransformerBlock: 2-10                 [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-55                   [1, 1024, 1600]           3,200\n",
       "│    │    └─MultiHeadAttention: 3-56          [1, 1024, 1600]           10,246,400\n",
       "│    │    └─Dropout: 3-57                     [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-58                   [1, 1024, 1600]           3,200\n",
       "│    │    └─FeedForward: 3-59                 [1, 1024, 1600]           20,488,000\n",
       "│    │    └─Dropout: 3-60                     [1, 1024, 1600]           --\n",
       "│    └─TransformerBlock: 2-11                 [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-61                   [1, 1024, 1600]           3,200\n",
       "│    │    └─MultiHeadAttention: 3-62          [1, 1024, 1600]           10,246,400\n",
       "│    │    └─Dropout: 3-63                     [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-64                   [1, 1024, 1600]           3,200\n",
       "│    │    └─FeedForward: 3-65                 [1, 1024, 1600]           20,488,000\n",
       "│    │    └─Dropout: 3-66                     [1, 1024, 1600]           --\n",
       "│    └─TransformerBlock: 2-12                 [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-67                   [1, 1024, 1600]           3,200\n",
       "│    │    └─MultiHeadAttention: 3-68          [1, 1024, 1600]           10,246,400\n",
       "│    │    └─Dropout: 3-69                     [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-70                   [1, 1024, 1600]           3,200\n",
       "│    │    └─FeedForward: 3-71                 [1, 1024, 1600]           20,488,000\n",
       "│    │    └─Dropout: 3-72                     [1, 1024, 1600]           --\n",
       "│    └─TransformerBlock: 2-13                 [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-73                   [1, 1024, 1600]           3,200\n",
       "│    │    └─MultiHeadAttention: 3-74          [1, 1024, 1600]           10,246,400\n",
       "│    │    └─Dropout: 3-75                     [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-76                   [1, 1024, 1600]           3,200\n",
       "│    │    └─FeedForward: 3-77                 [1, 1024, 1600]           20,488,000\n",
       "│    │    └─Dropout: 3-78                     [1, 1024, 1600]           --\n",
       "│    └─TransformerBlock: 2-14                 [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-79                   [1, 1024, 1600]           3,200\n",
       "│    │    └─MultiHeadAttention: 3-80          [1, 1024, 1600]           10,246,400\n",
       "│    │    └─Dropout: 3-81                     [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-82                   [1, 1024, 1600]           3,200\n",
       "│    │    └─FeedForward: 3-83                 [1, 1024, 1600]           20,488,000\n",
       "│    │    └─Dropout: 3-84                     [1, 1024, 1600]           --\n",
       "│    └─TransformerBlock: 2-15                 [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-85                   [1, 1024, 1600]           3,200\n",
       "│    │    └─MultiHeadAttention: 3-86          [1, 1024, 1600]           10,246,400\n",
       "│    │    └─Dropout: 3-87                     [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-88                   [1, 1024, 1600]           3,200\n",
       "│    │    └─FeedForward: 3-89                 [1, 1024, 1600]           20,488,000\n",
       "│    │    └─Dropout: 3-90                     [1, 1024, 1600]           --\n",
       "│    └─TransformerBlock: 2-16                 [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-91                   [1, 1024, 1600]           3,200\n",
       "│    │    └─MultiHeadAttention: 3-92          [1, 1024, 1600]           10,246,400\n",
       "│    │    └─Dropout: 3-93                     [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-94                   [1, 1024, 1600]           3,200\n",
       "│    │    └─FeedForward: 3-95                 [1, 1024, 1600]           20,488,000\n",
       "│    │    └─Dropout: 3-96                     [1, 1024, 1600]           --\n",
       "│    └─TransformerBlock: 2-17                 [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-97                   [1, 1024, 1600]           3,200\n",
       "│    │    └─MultiHeadAttention: 3-98          [1, 1024, 1600]           10,246,400\n",
       "│    │    └─Dropout: 3-99                     [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-100                  [1, 1024, 1600]           3,200\n",
       "│    │    └─FeedForward: 3-101                [1, 1024, 1600]           20,488,000\n",
       "│    │    └─Dropout: 3-102                    [1, 1024, 1600]           --\n",
       "│    └─TransformerBlock: 2-18                 [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-103                  [1, 1024, 1600]           3,200\n",
       "│    │    └─MultiHeadAttention: 3-104         [1, 1024, 1600]           10,246,400\n",
       "│    │    └─Dropout: 3-105                    [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-106                  [1, 1024, 1600]           3,200\n",
       "│    │    └─FeedForward: 3-107                [1, 1024, 1600]           20,488,000\n",
       "│    │    └─Dropout: 3-108                    [1, 1024, 1600]           --\n",
       "│    └─TransformerBlock: 2-19                 [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-109                  [1, 1024, 1600]           3,200\n",
       "│    │    └─MultiHeadAttention: 3-110         [1, 1024, 1600]           10,246,400\n",
       "│    │    └─Dropout: 3-111                    [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-112                  [1, 1024, 1600]           3,200\n",
       "│    │    └─FeedForward: 3-113                [1, 1024, 1600]           20,488,000\n",
       "│    │    └─Dropout: 3-114                    [1, 1024, 1600]           --\n",
       "│    └─TransformerBlock: 2-20                 [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-115                  [1, 1024, 1600]           3,200\n",
       "│    │    └─MultiHeadAttention: 3-116         [1, 1024, 1600]           10,246,400\n",
       "│    │    └─Dropout: 3-117                    [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-118                  [1, 1024, 1600]           3,200\n",
       "│    │    └─FeedForward: 3-119                [1, 1024, 1600]           20,488,000\n",
       "│    │    └─Dropout: 3-120                    [1, 1024, 1600]           --\n",
       "│    └─TransformerBlock: 2-21                 [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-121                  [1, 1024, 1600]           3,200\n",
       "│    │    └─MultiHeadAttention: 3-122         [1, 1024, 1600]           10,246,400\n",
       "│    │    └─Dropout: 3-123                    [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-124                  [1, 1024, 1600]           3,200\n",
       "│    │    └─FeedForward: 3-125                [1, 1024, 1600]           20,488,000\n",
       "│    │    └─Dropout: 3-126                    [1, 1024, 1600]           --\n",
       "│    └─TransformerBlock: 2-22                 [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-127                  [1, 1024, 1600]           3,200\n",
       "│    │    └─MultiHeadAttention: 3-128         [1, 1024, 1600]           10,246,400\n",
       "│    │    └─Dropout: 3-129                    [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-130                  [1, 1024, 1600]           3,200\n",
       "│    │    └─FeedForward: 3-131                [1, 1024, 1600]           20,488,000\n",
       "│    │    └─Dropout: 3-132                    [1, 1024, 1600]           --\n",
       "│    └─TransformerBlock: 2-23                 [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-133                  [1, 1024, 1600]           3,200\n",
       "│    │    └─MultiHeadAttention: 3-134         [1, 1024, 1600]           10,246,400\n",
       "│    │    └─Dropout: 3-135                    [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-136                  [1, 1024, 1600]           3,200\n",
       "│    │    └─FeedForward: 3-137                [1, 1024, 1600]           20,488,000\n",
       "│    │    └─Dropout: 3-138                    [1, 1024, 1600]           --\n",
       "│    └─TransformerBlock: 2-24                 [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-139                  [1, 1024, 1600]           3,200\n",
       "│    │    └─MultiHeadAttention: 3-140         [1, 1024, 1600]           10,246,400\n",
       "│    │    └─Dropout: 3-141                    [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-142                  [1, 1024, 1600]           3,200\n",
       "│    │    └─FeedForward: 3-143                [1, 1024, 1600]           20,488,000\n",
       "│    │    └─Dropout: 3-144                    [1, 1024, 1600]           --\n",
       "│    └─TransformerBlock: 2-25                 [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-145                  [1, 1024, 1600]           3,200\n",
       "│    │    └─MultiHeadAttention: 3-146         [1, 1024, 1600]           10,246,400\n",
       "│    │    └─Dropout: 3-147                    [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-148                  [1, 1024, 1600]           3,200\n",
       "│    │    └─FeedForward: 3-149                [1, 1024, 1600]           20,488,000\n",
       "│    │    └─Dropout: 3-150                    [1, 1024, 1600]           --\n",
       "│    └─TransformerBlock: 2-26                 [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-151                  [1, 1024, 1600]           3,200\n",
       "│    │    └─MultiHeadAttention: 3-152         [1, 1024, 1600]           10,246,400\n",
       "│    │    └─Dropout: 3-153                    [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-154                  [1, 1024, 1600]           3,200\n",
       "│    │    └─FeedForward: 3-155                [1, 1024, 1600]           20,488,000\n",
       "│    │    └─Dropout: 3-156                    [1, 1024, 1600]           --\n",
       "│    └─TransformerBlock: 2-27                 [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-157                  [1, 1024, 1600]           3,200\n",
       "│    │    └─MultiHeadAttention: 3-158         [1, 1024, 1600]           10,246,400\n",
       "│    │    └─Dropout: 3-159                    [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-160                  [1, 1024, 1600]           3,200\n",
       "│    │    └─FeedForward: 3-161                [1, 1024, 1600]           20,488,000\n",
       "│    │    └─Dropout: 3-162                    [1, 1024, 1600]           --\n",
       "│    └─TransformerBlock: 2-28                 [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-163                  [1, 1024, 1600]           3,200\n",
       "│    │    └─MultiHeadAttention: 3-164         [1, 1024, 1600]           10,246,400\n",
       "│    │    └─Dropout: 3-165                    [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-166                  [1, 1024, 1600]           3,200\n",
       "│    │    └─FeedForward: 3-167                [1, 1024, 1600]           20,488,000\n",
       "│    │    └─Dropout: 3-168                    [1, 1024, 1600]           --\n",
       "│    └─TransformerBlock: 2-29                 [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-169                  [1, 1024, 1600]           3,200\n",
       "│    │    └─MultiHeadAttention: 3-170         [1, 1024, 1600]           10,246,400\n",
       "│    │    └─Dropout: 3-171                    [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-172                  [1, 1024, 1600]           3,200\n",
       "│    │    └─FeedForward: 3-173                [1, 1024, 1600]           20,488,000\n",
       "│    │    └─Dropout: 3-174                    [1, 1024, 1600]           --\n",
       "│    └─TransformerBlock: 2-30                 [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-175                  [1, 1024, 1600]           3,200\n",
       "│    │    └─MultiHeadAttention: 3-176         [1, 1024, 1600]           10,246,400\n",
       "│    │    └─Dropout: 3-177                    [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-178                  [1, 1024, 1600]           3,200\n",
       "│    │    └─FeedForward: 3-179                [1, 1024, 1600]           20,488,000\n",
       "│    │    └─Dropout: 3-180                    [1, 1024, 1600]           --\n",
       "│    └─TransformerBlock: 2-31                 [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-181                  [1, 1024, 1600]           3,200\n",
       "│    │    └─MultiHeadAttention: 3-182         [1, 1024, 1600]           10,246,400\n",
       "│    │    └─Dropout: 3-183                    [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-184                  [1, 1024, 1600]           3,200\n",
       "│    │    └─FeedForward: 3-185                [1, 1024, 1600]           20,488,000\n",
       "│    │    └─Dropout: 3-186                    [1, 1024, 1600]           --\n",
       "│    └─TransformerBlock: 2-32                 [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-187                  [1, 1024, 1600]           3,200\n",
       "│    │    └─MultiHeadAttention: 3-188         [1, 1024, 1600]           10,246,400\n",
       "│    │    └─Dropout: 3-189                    [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-190                  [1, 1024, 1600]           3,200\n",
       "│    │    └─FeedForward: 3-191                [1, 1024, 1600]           20,488,000\n",
       "│    │    └─Dropout: 3-192                    [1, 1024, 1600]           --\n",
       "│    └─TransformerBlock: 2-33                 [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-193                  [1, 1024, 1600]           3,200\n",
       "│    │    └─MultiHeadAttention: 3-194         [1, 1024, 1600]           10,246,400\n",
       "│    │    └─Dropout: 3-195                    [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-196                  [1, 1024, 1600]           3,200\n",
       "│    │    └─FeedForward: 3-197                [1, 1024, 1600]           20,488,000\n",
       "│    │    └─Dropout: 3-198                    [1, 1024, 1600]           --\n",
       "│    └─TransformerBlock: 2-34                 [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-199                  [1, 1024, 1600]           3,200\n",
       "│    │    └─MultiHeadAttention: 3-200         [1, 1024, 1600]           10,246,400\n",
       "│    │    └─Dropout: 3-201                    [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-202                  [1, 1024, 1600]           3,200\n",
       "│    │    └─FeedForward: 3-203                [1, 1024, 1600]           20,488,000\n",
       "│    │    └─Dropout: 3-204                    [1, 1024, 1600]           --\n",
       "│    └─TransformerBlock: 2-35                 [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-205                  [1, 1024, 1600]           3,200\n",
       "│    │    └─MultiHeadAttention: 3-206         [1, 1024, 1600]           10,246,400\n",
       "│    │    └─Dropout: 3-207                    [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-208                  [1, 1024, 1600]           3,200\n",
       "│    │    └─FeedForward: 3-209                [1, 1024, 1600]           20,488,000\n",
       "│    │    └─Dropout: 3-210                    [1, 1024, 1600]           --\n",
       "│    └─TransformerBlock: 2-36                 [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-211                  [1, 1024, 1600]           3,200\n",
       "│    │    └─MultiHeadAttention: 3-212         [1, 1024, 1600]           10,246,400\n",
       "│    │    └─Dropout: 3-213                    [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-214                  [1, 1024, 1600]           3,200\n",
       "│    │    └─FeedForward: 3-215                [1, 1024, 1600]           20,488,000\n",
       "│    │    └─Dropout: 3-216                    [1, 1024, 1600]           --\n",
       "│    └─TransformerBlock: 2-37                 [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-217                  [1, 1024, 1600]           3,200\n",
       "│    │    └─MultiHeadAttention: 3-218         [1, 1024, 1600]           10,246,400\n",
       "│    │    └─Dropout: 3-219                    [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-220                  [1, 1024, 1600]           3,200\n",
       "│    │    └─FeedForward: 3-221                [1, 1024, 1600]           20,488,000\n",
       "│    │    └─Dropout: 3-222                    [1, 1024, 1600]           --\n",
       "│    └─TransformerBlock: 2-38                 [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-223                  [1, 1024, 1600]           3,200\n",
       "│    │    └─MultiHeadAttention: 3-224         [1, 1024, 1600]           10,246,400\n",
       "│    │    └─Dropout: 3-225                    [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-226                  [1, 1024, 1600]           3,200\n",
       "│    │    └─FeedForward: 3-227                [1, 1024, 1600]           20,488,000\n",
       "│    │    └─Dropout: 3-228                    [1, 1024, 1600]           --\n",
       "│    └─TransformerBlock: 2-39                 [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-229                  [1, 1024, 1600]           3,200\n",
       "│    │    └─MultiHeadAttention: 3-230         [1, 1024, 1600]           10,246,400\n",
       "│    │    └─Dropout: 3-231                    [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-232                  [1, 1024, 1600]           3,200\n",
       "│    │    └─FeedForward: 3-233                [1, 1024, 1600]           20,488,000\n",
       "│    │    └─Dropout: 3-234                    [1, 1024, 1600]           --\n",
       "│    └─TransformerBlock: 2-40                 [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-235                  [1, 1024, 1600]           3,200\n",
       "│    │    └─MultiHeadAttention: 3-236         [1, 1024, 1600]           10,246,400\n",
       "│    │    └─Dropout: 3-237                    [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-238                  [1, 1024, 1600]           3,200\n",
       "│    │    └─FeedForward: 3-239                [1, 1024, 1600]           20,488,000\n",
       "│    │    └─Dropout: 3-240                    [1, 1024, 1600]           --\n",
       "│    └─TransformerBlock: 2-41                 [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-241                  [1, 1024, 1600]           3,200\n",
       "│    │    └─MultiHeadAttention: 3-242         [1, 1024, 1600]           10,246,400\n",
       "│    │    └─Dropout: 3-243                    [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-244                  [1, 1024, 1600]           3,200\n",
       "│    │    └─FeedForward: 3-245                [1, 1024, 1600]           20,488,000\n",
       "│    │    └─Dropout: 3-246                    [1, 1024, 1600]           --\n",
       "│    └─TransformerBlock: 2-42                 [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-247                  [1, 1024, 1600]           3,200\n",
       "│    │    └─MultiHeadAttention: 3-248         [1, 1024, 1600]           10,246,400\n",
       "│    │    └─Dropout: 3-249                    [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-250                  [1, 1024, 1600]           3,200\n",
       "│    │    └─FeedForward: 3-251                [1, 1024, 1600]           20,488,000\n",
       "│    │    └─Dropout: 3-252                    [1, 1024, 1600]           --\n",
       "│    └─TransformerBlock: 2-43                 [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-253                  [1, 1024, 1600]           3,200\n",
       "│    │    └─MultiHeadAttention: 3-254         [1, 1024, 1600]           10,246,400\n",
       "│    │    └─Dropout: 3-255                    [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-256                  [1, 1024, 1600]           3,200\n",
       "│    │    └─FeedForward: 3-257                [1, 1024, 1600]           20,488,000\n",
       "│    │    └─Dropout: 3-258                    [1, 1024, 1600]           --\n",
       "│    └─TransformerBlock: 2-44                 [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-259                  [1, 1024, 1600]           3,200\n",
       "│    │    └─MultiHeadAttention: 3-260         [1, 1024, 1600]           10,246,400\n",
       "│    │    └─Dropout: 3-261                    [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-262                  [1, 1024, 1600]           3,200\n",
       "│    │    └─FeedForward: 3-263                [1, 1024, 1600]           20,488,000\n",
       "│    │    └─Dropout: 3-264                    [1, 1024, 1600]           --\n",
       "│    └─TransformerBlock: 2-45                 [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-265                  [1, 1024, 1600]           3,200\n",
       "│    │    └─MultiHeadAttention: 3-266         [1, 1024, 1600]           10,246,400\n",
       "│    │    └─Dropout: 3-267                    [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-268                  [1, 1024, 1600]           3,200\n",
       "│    │    └─FeedForward: 3-269                [1, 1024, 1600]           20,488,000\n",
       "│    │    └─Dropout: 3-270                    [1, 1024, 1600]           --\n",
       "│    └─TransformerBlock: 2-46                 [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-271                  [1, 1024, 1600]           3,200\n",
       "│    │    └─MultiHeadAttention: 3-272         [1, 1024, 1600]           10,246,400\n",
       "│    │    └─Dropout: 3-273                    [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-274                  [1, 1024, 1600]           3,200\n",
       "│    │    └─FeedForward: 3-275                [1, 1024, 1600]           20,488,000\n",
       "│    │    └─Dropout: 3-276                    [1, 1024, 1600]           --\n",
       "│    └─TransformerBlock: 2-47                 [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-277                  [1, 1024, 1600]           3,200\n",
       "│    │    └─MultiHeadAttention: 3-278         [1, 1024, 1600]           10,246,400\n",
       "│    │    └─Dropout: 3-279                    [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-280                  [1, 1024, 1600]           3,200\n",
       "│    │    └─FeedForward: 3-281                [1, 1024, 1600]           20,488,000\n",
       "│    │    └─Dropout: 3-282                    [1, 1024, 1600]           --\n",
       "│    └─TransformerBlock: 2-48                 [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-283                  [1, 1024, 1600]           3,200\n",
       "│    │    └─MultiHeadAttention: 3-284         [1, 1024, 1600]           10,246,400\n",
       "│    │    └─Dropout: 3-285                    [1, 1024, 1600]           --\n",
       "│    │    └─LayerNorm: 3-286                  [1, 1024, 1600]           3,200\n",
       "│    │    └─FeedForward: 3-287                [1, 1024, 1600]           20,488,000\n",
       "│    │    └─Dropout: 3-288                    [1, 1024, 1600]           --\n",
       "├─LayerNorm: 1-5                              [1, 1024, 1600]           3,200\n",
       "├─Linear: 1-6                                 [1, 1024, 50257]          80,411,200\n",
       "===============================================================================================\n",
       "Total params: 1,638,022,400\n",
       "Trainable params: 1,638,022,400\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 3.31\n",
       "===============================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 7371.63\n",
       "Params size (MB): 6552.09\n",
       "Estimated Total Size (MB): 13923.73\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "# You must provide an input_size so it can \"run\" a pass\n",
    "summary(gpt, input_size=(1, GPT_CONFIG[\"context_length\"]), dtypes=[torch.long])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42af5738-8c74-4941-8219-830203792b75",
   "metadata": {},
   "source": [
    "## configure device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8d819095-d6c3-4f54-ac99-aa1dfd526e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preferred device selected: mps\n",
      "Hardware status: (False, True)\n"
     ]
    }
   ],
   "source": [
    "# Create a status tuple to match against\n",
    "hardware_status = (torch.cuda.is_available(), torch.backends.mps.is_available())\n",
    "\n",
    "match hardware_status:\n",
    "    case (True, _):\n",
    "        # CUDA is available; prioritize it for maximum performance\n",
    "        device = torch.device(\"cuda\")\n",
    "    case (False, True):\n",
    "        # No CUDA, but MPS is available; preferred for Mac users\n",
    "        device = torch.device(\"mps\")\n",
    "    case _:\n",
    "        # Fallback for all other scenarios\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Preferred device selected: {device}\")\n",
    "print(f\"Hardware status: {hardware_status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899d74e1-eb23-4b10-bfc7-a80feb758924",
   "metadata": {},
   "source": [
    "## load the weights and copy them over to our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "00437312-9533-4a40-b35d-efdd235c4b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vocab_size': 50257, 'context_length': 1024, 'emb_dim': 1600, 'n_heads': 25, 'n_layers': 48, 'drop_rate': 0.1, 'qkv_bias': True, 'model_name': '1558M'}\n"
     ]
    }
   ],
   "source": [
    "print(GPT_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "72982050-caaf-4b8c-9e25-a1a0e895ee87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint: 100%|████████████████████████████████████████████████████████████████████████████████████| 77.0/77.0 [00:00<00:00, 72.9kiB/s]\n",
      "encoder.json: 100%|████████████████████████████████████████████████████████████████████████████████| 1.04M/1.04M [00:00<00:00, 2.33MiB/s]\n",
      "hparams.json: 100%|██████████████████████████████████████████████████████████████████████████████████| 91.0/91.0 [00:00<00:00, 62.3kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|██████████████████████████████████████████████████████████████| 6.23G/6.23G [03:47<00:00, 27.4MiB/s]\n",
      "model.ckpt.index: 100%|█████████████████████████████████████████████████████████████████████████████| 20.7k/20.7k [00:00<00:00, 404kiB/s]\n",
      "model.ckpt.meta: 100%|█████████████████████████████████████████████████████████████████████████████| 1.84M/1.84M [00:00<00:00, 3.25MiB/s]\n",
      "vocab.bpe: 100%|█████████████████████████████████████████████████████████████████████████████████████| 456k/456k [00:00<00:00, 1.59MiB/s]\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=GPT_CONFIG['model_name'], models_dir=\"gpt2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d300ac0f-b04c-4545-a97c-b9260aeb3d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8d084a14-850a-47bd-88aa-9a0cc0789677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device)\n",
    "True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06725739-3e00-4961-9178-d5b5d4f38530",
   "metadata": {},
   "source": [
    "## set up tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9c197e70-02b0-49d7-aba2-3f02669811da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd60977-ebfa-4c09-bd6c-e2240e3f3554",
   "metadata": {},
   "source": [
    "## run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0a7c9c86-2f98-4031-b697-5732e155a72b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt.eval()\n",
    "gpt.to(device)\n",
    "True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "62a54188-f622-4008-ac46-bebedd3fc755",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"Everybody loves a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afa90c7-6085-449d-8c99-cef9e84aa20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = text_to_token_ids(user_input, tokenizer)\n",
    "input_ids = input_ids.to(device)\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=gpt,\n",
    "    idx=input_ids,\n",
    "    max_new_tokens=50,\n",
    "    context_size=GPT_CONFIG[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cae1a2-6606-43ad-a3e9-06e230fb1637",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
