{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a402deb-6364-445b-b096-104f5db426de",
   "metadata": {},
   "source": [
    "# LLM inference\n",
    "\n",
    "Loads GPT2 weights of choice or saved weights and shows how to run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fbb54484-983f-451b-83c3-81f1f1cde261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "31f5d865-424f-419a-87aa-aed714dcbfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chapter04 import generate_text_simple\n",
    "from chapter05 import text_to_token_ids, token_ids_to_text, GPTModel, load_weights_into_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bb407e04-b604-4058-972d-50203c2be936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch loaded. version 2.9.1\n",
      "MPS available: True\n",
      "tiktoken version: 0.12.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "print(f'Torch loaded. version {torch.__version__}')\n",
    "print(f'MPS available: {torch.backends.mps.is_available()}')\n",
    "print(\"tiktoken version:\", version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15385f5-8b40-420c-a93f-26b4b4ef5d3a",
   "metadata": {},
   "source": [
    "## model config\n",
    "sizes available (\"124M\", \"355M\", \"774M\", \"1558M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "60cb71b6-864e-4f5e-9784-443f209802a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12, \"model_name\": \"124M\"},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16, \"model_name\": \"355M\"},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20, \"model_name\": \"774M\"},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25, \"model_name\": \"1558M\"},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a47d13a-7aaa-45f2-b0e3-171ba8582149",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "40315963-4317-46de-b996-50f3106b5bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2-large (774M)\"\n",
    "GPT_CONFIG.update(model_configs[model_name])\n",
    "GPT_CONFIG.update({\"qkv_bias\": True}) # gpt2 uses bias on the qkv weight parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d7a81a0-19b3-4dac-8181-704e7dfee573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt = GPTModel(GPT_CONFIG)\n",
    "gpt.eval()\n",
    "True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c765a3e4-5cbe-4e04-a026-c38cc7c86fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## torchinfo is a nice package to show more model information than pytorch print gives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6d90af8d-2133-465a-a8de-248ce7350b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "GPTModel                                      [1, 1024, 50257]          --\n",
       "├─Embedding: 1-1                              [1, 1024, 1280]           64,328,960\n",
       "├─Embedding: 1-2                              [1024, 1280]              1,310,720\n",
       "├─Dropout: 1-3                                [1, 1024, 1280]           --\n",
       "├─Sequential: 1-4                             [1, 1024, 1280]           --\n",
       "│    └─TransformerBlock: 2-1                  [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-1                    [1, 1024, 1280]           2,560\n",
       "│    │    └─MultiHeadAttention: 3-2           [1, 1024, 1280]           6,558,720\n",
       "│    │    └─Dropout: 3-3                      [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-4                    [1, 1024, 1280]           2,560\n",
       "│    │    └─FeedForward: 3-5                  [1, 1024, 1280]           13,113,600\n",
       "│    │    └─Dropout: 3-6                      [1, 1024, 1280]           --\n",
       "│    └─TransformerBlock: 2-2                  [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-7                    [1, 1024, 1280]           2,560\n",
       "│    │    └─MultiHeadAttention: 3-8           [1, 1024, 1280]           6,558,720\n",
       "│    │    └─Dropout: 3-9                      [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-10                   [1, 1024, 1280]           2,560\n",
       "│    │    └─FeedForward: 3-11                 [1, 1024, 1280]           13,113,600\n",
       "│    │    └─Dropout: 3-12                     [1, 1024, 1280]           --\n",
       "│    └─TransformerBlock: 2-3                  [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-13                   [1, 1024, 1280]           2,560\n",
       "│    │    └─MultiHeadAttention: 3-14          [1, 1024, 1280]           6,558,720\n",
       "│    │    └─Dropout: 3-15                     [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-16                   [1, 1024, 1280]           2,560\n",
       "│    │    └─FeedForward: 3-17                 [1, 1024, 1280]           13,113,600\n",
       "│    │    └─Dropout: 3-18                     [1, 1024, 1280]           --\n",
       "│    └─TransformerBlock: 2-4                  [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-19                   [1, 1024, 1280]           2,560\n",
       "│    │    └─MultiHeadAttention: 3-20          [1, 1024, 1280]           6,558,720\n",
       "│    │    └─Dropout: 3-21                     [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-22                   [1, 1024, 1280]           2,560\n",
       "│    │    └─FeedForward: 3-23                 [1, 1024, 1280]           13,113,600\n",
       "│    │    └─Dropout: 3-24                     [1, 1024, 1280]           --\n",
       "│    └─TransformerBlock: 2-5                  [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-25                   [1, 1024, 1280]           2,560\n",
       "│    │    └─MultiHeadAttention: 3-26          [1, 1024, 1280]           6,558,720\n",
       "│    │    └─Dropout: 3-27                     [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-28                   [1, 1024, 1280]           2,560\n",
       "│    │    └─FeedForward: 3-29                 [1, 1024, 1280]           13,113,600\n",
       "│    │    └─Dropout: 3-30                     [1, 1024, 1280]           --\n",
       "│    └─TransformerBlock: 2-6                  [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-31                   [1, 1024, 1280]           2,560\n",
       "│    │    └─MultiHeadAttention: 3-32          [1, 1024, 1280]           6,558,720\n",
       "│    │    └─Dropout: 3-33                     [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-34                   [1, 1024, 1280]           2,560\n",
       "│    │    └─FeedForward: 3-35                 [1, 1024, 1280]           13,113,600\n",
       "│    │    └─Dropout: 3-36                     [1, 1024, 1280]           --\n",
       "│    └─TransformerBlock: 2-7                  [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-37                   [1, 1024, 1280]           2,560\n",
       "│    │    └─MultiHeadAttention: 3-38          [1, 1024, 1280]           6,558,720\n",
       "│    │    └─Dropout: 3-39                     [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-40                   [1, 1024, 1280]           2,560\n",
       "│    │    └─FeedForward: 3-41                 [1, 1024, 1280]           13,113,600\n",
       "│    │    └─Dropout: 3-42                     [1, 1024, 1280]           --\n",
       "│    └─TransformerBlock: 2-8                  [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-43                   [1, 1024, 1280]           2,560\n",
       "│    │    └─MultiHeadAttention: 3-44          [1, 1024, 1280]           6,558,720\n",
       "│    │    └─Dropout: 3-45                     [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-46                   [1, 1024, 1280]           2,560\n",
       "│    │    └─FeedForward: 3-47                 [1, 1024, 1280]           13,113,600\n",
       "│    │    └─Dropout: 3-48                     [1, 1024, 1280]           --\n",
       "│    └─TransformerBlock: 2-9                  [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-49                   [1, 1024, 1280]           2,560\n",
       "│    │    └─MultiHeadAttention: 3-50          [1, 1024, 1280]           6,558,720\n",
       "│    │    └─Dropout: 3-51                     [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-52                   [1, 1024, 1280]           2,560\n",
       "│    │    └─FeedForward: 3-53                 [1, 1024, 1280]           13,113,600\n",
       "│    │    └─Dropout: 3-54                     [1, 1024, 1280]           --\n",
       "│    └─TransformerBlock: 2-10                 [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-55                   [1, 1024, 1280]           2,560\n",
       "│    │    └─MultiHeadAttention: 3-56          [1, 1024, 1280]           6,558,720\n",
       "│    │    └─Dropout: 3-57                     [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-58                   [1, 1024, 1280]           2,560\n",
       "│    │    └─FeedForward: 3-59                 [1, 1024, 1280]           13,113,600\n",
       "│    │    └─Dropout: 3-60                     [1, 1024, 1280]           --\n",
       "│    └─TransformerBlock: 2-11                 [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-61                   [1, 1024, 1280]           2,560\n",
       "│    │    └─MultiHeadAttention: 3-62          [1, 1024, 1280]           6,558,720\n",
       "│    │    └─Dropout: 3-63                     [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-64                   [1, 1024, 1280]           2,560\n",
       "│    │    └─FeedForward: 3-65                 [1, 1024, 1280]           13,113,600\n",
       "│    │    └─Dropout: 3-66                     [1, 1024, 1280]           --\n",
       "│    └─TransformerBlock: 2-12                 [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-67                   [1, 1024, 1280]           2,560\n",
       "│    │    └─MultiHeadAttention: 3-68          [1, 1024, 1280]           6,558,720\n",
       "│    │    └─Dropout: 3-69                     [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-70                   [1, 1024, 1280]           2,560\n",
       "│    │    └─FeedForward: 3-71                 [1, 1024, 1280]           13,113,600\n",
       "│    │    └─Dropout: 3-72                     [1, 1024, 1280]           --\n",
       "│    └─TransformerBlock: 2-13                 [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-73                   [1, 1024, 1280]           2,560\n",
       "│    │    └─MultiHeadAttention: 3-74          [1, 1024, 1280]           6,558,720\n",
       "│    │    └─Dropout: 3-75                     [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-76                   [1, 1024, 1280]           2,560\n",
       "│    │    └─FeedForward: 3-77                 [1, 1024, 1280]           13,113,600\n",
       "│    │    └─Dropout: 3-78                     [1, 1024, 1280]           --\n",
       "│    └─TransformerBlock: 2-14                 [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-79                   [1, 1024, 1280]           2,560\n",
       "│    │    └─MultiHeadAttention: 3-80          [1, 1024, 1280]           6,558,720\n",
       "│    │    └─Dropout: 3-81                     [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-82                   [1, 1024, 1280]           2,560\n",
       "│    │    └─FeedForward: 3-83                 [1, 1024, 1280]           13,113,600\n",
       "│    │    └─Dropout: 3-84                     [1, 1024, 1280]           --\n",
       "│    └─TransformerBlock: 2-15                 [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-85                   [1, 1024, 1280]           2,560\n",
       "│    │    └─MultiHeadAttention: 3-86          [1, 1024, 1280]           6,558,720\n",
       "│    │    └─Dropout: 3-87                     [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-88                   [1, 1024, 1280]           2,560\n",
       "│    │    └─FeedForward: 3-89                 [1, 1024, 1280]           13,113,600\n",
       "│    │    └─Dropout: 3-90                     [1, 1024, 1280]           --\n",
       "│    └─TransformerBlock: 2-16                 [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-91                   [1, 1024, 1280]           2,560\n",
       "│    │    └─MultiHeadAttention: 3-92          [1, 1024, 1280]           6,558,720\n",
       "│    │    └─Dropout: 3-93                     [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-94                   [1, 1024, 1280]           2,560\n",
       "│    │    └─FeedForward: 3-95                 [1, 1024, 1280]           13,113,600\n",
       "│    │    └─Dropout: 3-96                     [1, 1024, 1280]           --\n",
       "│    └─TransformerBlock: 2-17                 [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-97                   [1, 1024, 1280]           2,560\n",
       "│    │    └─MultiHeadAttention: 3-98          [1, 1024, 1280]           6,558,720\n",
       "│    │    └─Dropout: 3-99                     [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-100                  [1, 1024, 1280]           2,560\n",
       "│    │    └─FeedForward: 3-101                [1, 1024, 1280]           13,113,600\n",
       "│    │    └─Dropout: 3-102                    [1, 1024, 1280]           --\n",
       "│    └─TransformerBlock: 2-18                 [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-103                  [1, 1024, 1280]           2,560\n",
       "│    │    └─MultiHeadAttention: 3-104         [1, 1024, 1280]           6,558,720\n",
       "│    │    └─Dropout: 3-105                    [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-106                  [1, 1024, 1280]           2,560\n",
       "│    │    └─FeedForward: 3-107                [1, 1024, 1280]           13,113,600\n",
       "│    │    └─Dropout: 3-108                    [1, 1024, 1280]           --\n",
       "│    └─TransformerBlock: 2-19                 [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-109                  [1, 1024, 1280]           2,560\n",
       "│    │    └─MultiHeadAttention: 3-110         [1, 1024, 1280]           6,558,720\n",
       "│    │    └─Dropout: 3-111                    [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-112                  [1, 1024, 1280]           2,560\n",
       "│    │    └─FeedForward: 3-113                [1, 1024, 1280]           13,113,600\n",
       "│    │    └─Dropout: 3-114                    [1, 1024, 1280]           --\n",
       "│    └─TransformerBlock: 2-20                 [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-115                  [1, 1024, 1280]           2,560\n",
       "│    │    └─MultiHeadAttention: 3-116         [1, 1024, 1280]           6,558,720\n",
       "│    │    └─Dropout: 3-117                    [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-118                  [1, 1024, 1280]           2,560\n",
       "│    │    └─FeedForward: 3-119                [1, 1024, 1280]           13,113,600\n",
       "│    │    └─Dropout: 3-120                    [1, 1024, 1280]           --\n",
       "│    └─TransformerBlock: 2-21                 [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-121                  [1, 1024, 1280]           2,560\n",
       "│    │    └─MultiHeadAttention: 3-122         [1, 1024, 1280]           6,558,720\n",
       "│    │    └─Dropout: 3-123                    [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-124                  [1, 1024, 1280]           2,560\n",
       "│    │    └─FeedForward: 3-125                [1, 1024, 1280]           13,113,600\n",
       "│    │    └─Dropout: 3-126                    [1, 1024, 1280]           --\n",
       "│    └─TransformerBlock: 2-22                 [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-127                  [1, 1024, 1280]           2,560\n",
       "│    │    └─MultiHeadAttention: 3-128         [1, 1024, 1280]           6,558,720\n",
       "│    │    └─Dropout: 3-129                    [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-130                  [1, 1024, 1280]           2,560\n",
       "│    │    └─FeedForward: 3-131                [1, 1024, 1280]           13,113,600\n",
       "│    │    └─Dropout: 3-132                    [1, 1024, 1280]           --\n",
       "│    └─TransformerBlock: 2-23                 [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-133                  [1, 1024, 1280]           2,560\n",
       "│    │    └─MultiHeadAttention: 3-134         [1, 1024, 1280]           6,558,720\n",
       "│    │    └─Dropout: 3-135                    [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-136                  [1, 1024, 1280]           2,560\n",
       "│    │    └─FeedForward: 3-137                [1, 1024, 1280]           13,113,600\n",
       "│    │    └─Dropout: 3-138                    [1, 1024, 1280]           --\n",
       "│    └─TransformerBlock: 2-24                 [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-139                  [1, 1024, 1280]           2,560\n",
       "│    │    └─MultiHeadAttention: 3-140         [1, 1024, 1280]           6,558,720\n",
       "│    │    └─Dropout: 3-141                    [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-142                  [1, 1024, 1280]           2,560\n",
       "│    │    └─FeedForward: 3-143                [1, 1024, 1280]           13,113,600\n",
       "│    │    └─Dropout: 3-144                    [1, 1024, 1280]           --\n",
       "│    └─TransformerBlock: 2-25                 [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-145                  [1, 1024, 1280]           2,560\n",
       "│    │    └─MultiHeadAttention: 3-146         [1, 1024, 1280]           6,558,720\n",
       "│    │    └─Dropout: 3-147                    [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-148                  [1, 1024, 1280]           2,560\n",
       "│    │    └─FeedForward: 3-149                [1, 1024, 1280]           13,113,600\n",
       "│    │    └─Dropout: 3-150                    [1, 1024, 1280]           --\n",
       "│    └─TransformerBlock: 2-26                 [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-151                  [1, 1024, 1280]           2,560\n",
       "│    │    └─MultiHeadAttention: 3-152         [1, 1024, 1280]           6,558,720\n",
       "│    │    └─Dropout: 3-153                    [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-154                  [1, 1024, 1280]           2,560\n",
       "│    │    └─FeedForward: 3-155                [1, 1024, 1280]           13,113,600\n",
       "│    │    └─Dropout: 3-156                    [1, 1024, 1280]           --\n",
       "│    └─TransformerBlock: 2-27                 [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-157                  [1, 1024, 1280]           2,560\n",
       "│    │    └─MultiHeadAttention: 3-158         [1, 1024, 1280]           6,558,720\n",
       "│    │    └─Dropout: 3-159                    [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-160                  [1, 1024, 1280]           2,560\n",
       "│    │    └─FeedForward: 3-161                [1, 1024, 1280]           13,113,600\n",
       "│    │    └─Dropout: 3-162                    [1, 1024, 1280]           --\n",
       "│    └─TransformerBlock: 2-28                 [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-163                  [1, 1024, 1280]           2,560\n",
       "│    │    └─MultiHeadAttention: 3-164         [1, 1024, 1280]           6,558,720\n",
       "│    │    └─Dropout: 3-165                    [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-166                  [1, 1024, 1280]           2,560\n",
       "│    │    └─FeedForward: 3-167                [1, 1024, 1280]           13,113,600\n",
       "│    │    └─Dropout: 3-168                    [1, 1024, 1280]           --\n",
       "│    └─TransformerBlock: 2-29                 [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-169                  [1, 1024, 1280]           2,560\n",
       "│    │    └─MultiHeadAttention: 3-170         [1, 1024, 1280]           6,558,720\n",
       "│    │    └─Dropout: 3-171                    [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-172                  [1, 1024, 1280]           2,560\n",
       "│    │    └─FeedForward: 3-173                [1, 1024, 1280]           13,113,600\n",
       "│    │    └─Dropout: 3-174                    [1, 1024, 1280]           --\n",
       "│    └─TransformerBlock: 2-30                 [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-175                  [1, 1024, 1280]           2,560\n",
       "│    │    └─MultiHeadAttention: 3-176         [1, 1024, 1280]           6,558,720\n",
       "│    │    └─Dropout: 3-177                    [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-178                  [1, 1024, 1280]           2,560\n",
       "│    │    └─FeedForward: 3-179                [1, 1024, 1280]           13,113,600\n",
       "│    │    └─Dropout: 3-180                    [1, 1024, 1280]           --\n",
       "│    └─TransformerBlock: 2-31                 [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-181                  [1, 1024, 1280]           2,560\n",
       "│    │    └─MultiHeadAttention: 3-182         [1, 1024, 1280]           6,558,720\n",
       "│    │    └─Dropout: 3-183                    [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-184                  [1, 1024, 1280]           2,560\n",
       "│    │    └─FeedForward: 3-185                [1, 1024, 1280]           13,113,600\n",
       "│    │    └─Dropout: 3-186                    [1, 1024, 1280]           --\n",
       "│    └─TransformerBlock: 2-32                 [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-187                  [1, 1024, 1280]           2,560\n",
       "│    │    └─MultiHeadAttention: 3-188         [1, 1024, 1280]           6,558,720\n",
       "│    │    └─Dropout: 3-189                    [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-190                  [1, 1024, 1280]           2,560\n",
       "│    │    └─FeedForward: 3-191                [1, 1024, 1280]           13,113,600\n",
       "│    │    └─Dropout: 3-192                    [1, 1024, 1280]           --\n",
       "│    └─TransformerBlock: 2-33                 [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-193                  [1, 1024, 1280]           2,560\n",
       "│    │    └─MultiHeadAttention: 3-194         [1, 1024, 1280]           6,558,720\n",
       "│    │    └─Dropout: 3-195                    [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-196                  [1, 1024, 1280]           2,560\n",
       "│    │    └─FeedForward: 3-197                [1, 1024, 1280]           13,113,600\n",
       "│    │    └─Dropout: 3-198                    [1, 1024, 1280]           --\n",
       "│    └─TransformerBlock: 2-34                 [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-199                  [1, 1024, 1280]           2,560\n",
       "│    │    └─MultiHeadAttention: 3-200         [1, 1024, 1280]           6,558,720\n",
       "│    │    └─Dropout: 3-201                    [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-202                  [1, 1024, 1280]           2,560\n",
       "│    │    └─FeedForward: 3-203                [1, 1024, 1280]           13,113,600\n",
       "│    │    └─Dropout: 3-204                    [1, 1024, 1280]           --\n",
       "│    └─TransformerBlock: 2-35                 [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-205                  [1, 1024, 1280]           2,560\n",
       "│    │    └─MultiHeadAttention: 3-206         [1, 1024, 1280]           6,558,720\n",
       "│    │    └─Dropout: 3-207                    [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-208                  [1, 1024, 1280]           2,560\n",
       "│    │    └─FeedForward: 3-209                [1, 1024, 1280]           13,113,600\n",
       "│    │    └─Dropout: 3-210                    [1, 1024, 1280]           --\n",
       "│    └─TransformerBlock: 2-36                 [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-211                  [1, 1024, 1280]           2,560\n",
       "│    │    └─MultiHeadAttention: 3-212         [1, 1024, 1280]           6,558,720\n",
       "│    │    └─Dropout: 3-213                    [1, 1024, 1280]           --\n",
       "│    │    └─LayerNorm: 3-214                  [1, 1024, 1280]           2,560\n",
       "│    │    └─FeedForward: 3-215                [1, 1024, 1280]           13,113,600\n",
       "│    │    └─Dropout: 3-216                    [1, 1024, 1280]           --\n",
       "├─LayerNorm: 1-5                              [1, 1024, 1280]           2,560\n",
       "├─Linear: 1-6                                 [1, 1024, 50257]          64,328,960\n",
       "===============================================================================================\n",
       "Total params: 838,359,040\n",
       "Trainable params: 838,359,040\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 2.18\n",
       "===============================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 4595.52\n",
       "Params size (MB): 3353.44\n",
       "Estimated Total Size (MB): 7948.97\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "# You must provide an input_size so it can \"run\" a pass\n",
    "summary(gpt, input_size=(1, GPT_CONFIG[\"context_length\"]), dtypes=[torch.long])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42af5738-8c74-4941-8219-830203792b75",
   "metadata": {},
   "source": [
    "## configure device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8d819095-d6c3-4f54-ac99-aa1dfd526e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preferred device selected: mps\n",
      "Hardware status: (False, True)\n"
     ]
    }
   ],
   "source": [
    "# Create a status tuple to match against\n",
    "hardware_status = (torch.cuda.is_available(), torch.backends.mps.is_available())\n",
    "\n",
    "match hardware_status:\n",
    "    case (True, _):\n",
    "        # CUDA is available; prioritize it for maximum performance\n",
    "        device = torch.device(\"cuda\")\n",
    "    case (False, True):\n",
    "        # No CUDA, but MPS is available; preferred for Mac users\n",
    "        device = torch.device(\"mps\")\n",
    "    case _:\n",
    "        # Fallback for all other scenarios\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Preferred device selected: {device}\")\n",
    "print(f\"Hardware status: {hardware_status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899d74e1-eb23-4b10-bfc7-a80feb758924",
   "metadata": {},
   "source": [
    "## load the weights and copy them over to our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "00437312-9533-4a40-b35d-efdd235c4b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vocab_size': 50257, 'context_length': 1024, 'emb_dim': 1280, 'n_heads': 20, 'n_layers': 36, 'drop_rate': 0.1, 'qkv_bias': True, 'model_name': '774M'}\n"
     ]
    }
   ],
   "source": [
    "print(GPT_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "72982050-caaf-4b8c-9e25-a1a0e895ee87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/774M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/774M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/774M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/774M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/774M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/774M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/774M/vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=GPT_CONFIG['model_name'], models_dir=\"gpt2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d300ac0f-b04c-4545-a97c-b9260aeb3d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8d084a14-850a-47bd-88aa-9a0cc0789677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device)\n",
    "True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06725739-3e00-4961-9178-d5b5d4f38530",
   "metadata": {},
   "source": [
    "## set up tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9c197e70-02b0-49d7-aba2-3f02669811da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd60977-ebfa-4c09-bd6c-e2240e3f3554",
   "metadata": {},
   "source": [
    "## run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0a7c9c86-2f98-4031-b697-5732e155a72b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt.eval()\n",
    "gpt.to(device)\n",
    "True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "76cae1a2-6606-43ad-a3e9-06e230fb1637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size,\n",
    "             temperature=0.0, top_k=None, eos_id=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(\n",
    "                logits < min_val,\n",
    "                torch.tensor(float('-inf')).to(logits.device),\n",
    "                logits\n",
    "            )\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "62a54188-f622-4008-ac46-bebedd3fc755",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"The main problem with Cars is\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9041194c-48ee-4b7a-a32d-74d0a36f2f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " The main problem with Cars is that it's a game that's not really about cars. It's about the people who drive them. It's about the\n"
     ]
    }
   ],
   "source": [
    "input_ids = text_to_token_ids(user_input, tokenizer)\n",
    "input_ids = input_ids.to(device)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=input_ids,\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG[\"context_length\"],\n",
    "    top_k=15,\n",
    "    temperature=0.1\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70beafa5-d1d4-4d07-a119-00314f66ec44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
