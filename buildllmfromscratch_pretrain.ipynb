{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HbB0-vDJ0zCj"
   },
   "source": [
    "In this notebook I build chapter 4 of build your own llm from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Lz3T_Vjf1BjM"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch loaded. version 2.9.1\n",
      "MPS available: True\n",
      "tiktoken version: 0.12.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "print(f'Torch loaded. version {torch.__version__}')\n",
    "print(f'MPS available: {torch.backends.mps.is_available()}')\n",
    "print(\"tiktoken version:\", version(\"tiktoken\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "FxidckYs04a1"
   },
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "kv6yQuMXYj4E"
   },
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9PwvB5C-1JWR"
   },
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "a7sX_yz5aKjg"
   },
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "prrXLDvFe10q"
   },
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Msnu2M0gik1Q"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out,\n",
    "                 context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \\\n",
    "            \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length),\n",
    "                       diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(\n",
    "            b, num_tokens, self.num_heads, self.head_dim\n",
    "        )\n",
    "\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(2, 3)\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "\n",
    "        attn_weights = torch.softmax(\n",
    "            attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
    "\n",
    "        context_vec = context_vec.contiguous().view(\n",
    "            b, num_tokens, self.d_out\n",
    "        )\n",
    "        context_vec = self.out_proj(context_vec)\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "aPKq0To5rerS"
   },
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "rP9jkdMYrkg4"
   },
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        # Token embeddings come first from the input...\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        # Position embeddings\n",
    "        pos_embeds = self.pos_emb(\n",
    "            torch.arange(seq_len, device=in_idx.device) # what's this for?\n",
    "        )\n",
    "        # Add the token and position embeddings...\n",
    "        x = tok_embeds + pos_embeds\n",
    "        # First drop out\n",
    "        x = self.drop_emb(x)\n",
    "        # Transformer blocks (* number of layers, 12 in the example)\n",
    "        x = self.trf_blocks(x)\n",
    "        # Final later norm\n",
    "        x = self.final_norm(x)\n",
    "        # output the logits\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dIPghaSi8WM_"
   },
   "source": [
    "Initialize the model in inference mode (eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nJNQvJ0n0RLU",
    "outputId": "34232c2a-e5e6-49e9-f6ca-73445515e521"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()\n",
    "True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9MQmFSuD-egC"
   },
   "source": [
    "Text handling input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "8IDH6foZySg9"
   },
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx,\n",
    "                         max_new_tokens, context_size):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:] # Crop to the context size\n",
    "        with torch.no_grad(): # Disable auto grad for prediction\n",
    "            logits = model(idx_cond) # Get the logits for the the input\n",
    "\n",
    "        # Focus ONLY on the last time step\n",
    "        # (Batch, sequence, tokens) -> we want the last index of Internal_Length\n",
    "\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # Softmax - turn the logits into probabilities\n",
    "        probas = torch.softmax(logits, dim=-1)\n",
    "        # Take the most probable new token as the next token...\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "        # Append it to the input and continue the loop\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "afVulB7--gYA",
    "outputId": "08b75d4b-ceae-43e7-eded-11ae6dd0f4d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnÙ… refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pxV1bgVzgb6T"
   },
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "yJitZUWS-iP7"
   },
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "HBg0Ftyzgdmh"
   },
   "outputs": [],
   "source": [
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107, 588, 11311]])  #  \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9kLCuqg-hT3j"
   },
   "source": [
    "calculate probabilities of next token for each input. note that shape is 2 (batches, 3 context length and 50257 vocab size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MMsctsTFghZ3",
    "outputId": "8c7fd04e-fe7a-4323-c803-736f3dc270bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(probas.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "meBwqr7uhbwK"
   },
   "source": [
    "probablities of next token for the target \\output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DkIy_ioKhQT_",
    "outputId": "edeb5c06-fae6-4e2b-abfa-c40e47fe2df5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o4Qic0zjhiCg",
    "outputId": "452d9215-3bbb-4a2b-a83d-6e5f8aac1d2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1:\"\n",
    "      f\" {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nircLM9hjQ83"
   },
   "source": [
    "For each of the two input texts, we can print the initial softmax probability scores corresponding to the target tokens using the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2cz5i570iwjP",
    "outputId": "eb56775b-ec61-4ebb-ee05-f0036978f5ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.4541e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oXLoMtW_jfTU"
   },
   "source": [
    "calculate the log probablities (better for gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lZA8SfIhjgT6",
    "outputId": "cacfc7e5-35ad-4a6e-c997-3c5210f469bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gC3l--vbmPMi"
   },
   "source": [
    "get the average across all the guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "slKfsUabjgj0",
    "outputId": "c61dd517-7a66-4124-84a9-7632a2c9bbfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7940)\n"
     ]
    }
   ],
   "source": [
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Q4Cq9DNmVn4"
   },
   "source": [
    "note that we deal with the negative log for training purposes, trying to get it to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZyqoEoC3mRgi",
    "outputId": "d000d3a7-19ed-404d-9490-44f5bc893db2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EzClaREJmdig"
   },
   "source": [
    "remembering the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qre-1p1ymUtY",
    "outputId": "90a87f29-3dab-4ec2-a232-adb3092ee676"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"Logits shape:\", logits.shape)\n",
    "print(\"Targets shape:\", targets.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8r0ZdfjmmV0"
   },
   "source": [
    "flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4lB08B3CmehM",
    "outputId": "836bb304-9817-4687-e7a6-69ed72a84871"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DVKEZu5Mn2rd"
   },
   "source": [
    "pytorch has us covered, cross entropy loss does the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u189H4VOmnEP",
    "outputId": "0f12da10-98ca-481e-d34f-00b6de78c14c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hzjQ1UEorZv_"
   },
   "source": [
    "perplexity - e^loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vmeL2u3Wn7AO",
    "outputId": "37108688-623a-4f87-f9c8-12aaa6561bf5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(48725.8203)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IySasmf2vQR5"
   },
   "source": [
    "okay! now we pretrain on the story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "8BkcsJOTvR-E"
   },
   "outputs": [],
   "source": [
    "file_path = \"./data/the-verdict.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ieQ1TAcpw_pm",
    "outputId": "02cbbcce-cde5-491b-df74-2d7300a4d11d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20480\n",
      "Tokens: 5146\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CAVE8uc1xboI"
   },
   "source": [
    "start writing the data loader, we split the data into a training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "51W7N9R6xGYg"
   },
   "outputs": [],
   "source": [
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Q9Xa6SnxwCJ"
   },
   "source": [
    "We need the data loader from chapter 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "kVO7kHK_xdsV"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # Convert the incoming text to tokens\n",
    "        token_ids = tokenizer.encode(txt)\n",
    "\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n",
    "\n",
    "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
    "                         stride=128, shuffle=True, drop_last=True,\n",
    "                         num_workers=0):\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return dataloader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uxqv3v6voa6S"
   },
   "source": [
    "Note the batch size 2, batch sizes of 1024 are not uncommon irl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "REmIs7lkxx0_"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(123) # we did this earlier but it's fine\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7-5lYd0olMG"
   },
   "source": [
    "test the data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TvlfZg6oyCYM",
    "outputId": "7deb2f41-983e-4386-c8c4-ad5fdb2b2dcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZX164bQo088"
   },
   "source": [
    "this trains a batch, runs it through the model and calculates the cross entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "UcT9g4KNomW6"
   },
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = nn.functional.cross_entropy(\n",
    "        logits.flatten(0, 1), target_batch.flatten()\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pHMjU2Ekphfc"
   },
   "source": [
    "this function iterates over all the batches and calculates the total loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "V9Fpj1EYo7z7"
   },
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-RcrLIQpvMd"
   },
   "source": [
    "run a training sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p5qzNJuApmE6",
    "outputId": "1bc46f12-7cf8-4120-a75f-9d35af256b25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.987583690219456\n",
      "Validation loss: 10.983160018920898\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vfo5bl5MqmfA"
   },
   "source": [
    "now we implement the high level training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "ym1gkTnfpxG-"
   },
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader,\n",
    "                       optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # num_epochs is the number of passes over the training data\n",
    "    for epoch in range(num_epochs):\n",
    "        # set the model to training mode\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            # reset the gradients\n",
    "            optimizer.zero_grad()\n",
    "            # calculate the loss as above\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, \"\n",
    "                      f\"Val loss {val_loss:.3f}\"\n",
    "                )\n",
    "\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8kqcMp5BsaYw"
   },
   "source": [
    "the above calls this to train the model over one batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "shMAECUjqp3M"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(\n",
    "            train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_loss = calc_loss_loader(\n",
    "            val_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yr5An4oHsk8W"
   },
   "source": [
    "helper to print the progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "HUrEJXsTsdw5"
   },
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jVxqiH8ls4OO"
   },
   "source": [
    "let's do a test run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o-eGMjGYsjd9",
    "outputId": "42bc4aa0-5f67-4bdc-d3fe-45608ab2008c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.781, Val loss 9.932\n",
      "Ep 1 (Step 000005): Train loss 8.111, Val loss 8.339\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 6.661, Val loss 7.048\n",
      "Ep 2 (Step 000015): Train loss 5.961, Val loss 6.616\n",
      "Every effort moves you, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and,, and, and,\n",
      "Ep 3 (Step 000020): Train loss 5.726, Val loss 6.629\n",
      "Ep 3 (Step 000025): Train loss 5.201, Val loss 6.348\n",
      "Every effort moves you, and I had been.                                            \n",
      "Ep 4 (Step 000030): Train loss 4.417, Val loss 6.278\n",
      "Ep 4 (Step 000035): Train loss 4.069, Val loss 6.225\n",
      "Every effort moves you know the                          \"I he had the donkey and I had the and I had the donkey and down the room, I had\n",
      "Ep 5 (Step 000040): Train loss 3.732, Val loss 6.158\n",
      "Every effort moves you know it was not that the picture--I had the fact by the last I had been--his, and in the            \"Oh, and he said, and down the room, and in\n",
      "Ep 6 (Step 000045): Train loss 2.850, Val loss 6.178\n",
      "Ep 6 (Step 000050): Train loss 2.427, Val loss 6.140\n",
      "Every effort moves you know,\" was one of the picture. The--I had a little of a little: \"Yes, and in fact, and in the picture was, and I had been at my elbow and as his pictures, and down the room, I had\n",
      "Ep 7 (Step 000055): Train loss 2.104, Val loss 6.133\n",
      "Ep 7 (Step 000060): Train loss 1.882, Val loss 6.232\n",
      "Every effort moves you know,\" was one of the picture for nothing--I told Mrs.  \"I was no--as! The women had been, in the moment--as Jack himself, as once one had been the donkey, and were, and in his\n",
      "Ep 8 (Step 000065): Train loss 1.320, Val loss 6.236\n",
      "Ep 8 (Step 000070): Train loss 0.985, Val loss 6.240\n",
      "Every effort moves you know,\" was one of the axioms he had been the tips of a self-confident moustache, I felt to see a smile behind his close grayish beard--as if he had the donkey. \"strongest,\" as his\n",
      "Ep 9 (Step 000075): Train loss 0.717, Val loss 6.291\n",
      "Ep 9 (Step 000080): Train loss 0.541, Val loss 6.391\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back the window-curtains, I had the donkey. \"There were days when I\n",
      "Ep 10 (Step 000085): Train loss 0.391, Val loss 6.449\n",
      "Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed luncheon-table, when, on a later day, I had again run over from Monte Carlo; and Mrs. Gis\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(\n",
    "     model.parameters(),\n",
    "    lr=0.0004, weight_decay=0.1\n",
    ")\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uDJPQDt9dVQy"
   },
   "source": [
    "visualization of training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "ZdvNYLMds6DL",
    "outputId": "391ac4ed-96b8-4209-cde6-774c66ecdb67"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(\n",
    "        epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\"\n",
    "    )\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZhbON2adsGBJ"
   },
   "source": [
    "Decoding strategies to reduce randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jPalYFS9dXWo",
    "outputId": "6a293c1a-e88c-415e-9942-74b228d6fba0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9nsIcAjsVYp"
   },
   "source": [
    "Now we are in eval (inference) mode, let's do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "invhS2ZKsIiV",
    "outputId": "6bdb01d2-7836-4064-b047-6590a1140833"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed lun\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B3MMYCWPia3n"
   },
   "source": [
    "here's generate incorporating topk and temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "Mq1fFD2HsYkh"
   },
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size,\n",
    "             temperature=0.0, top_k=None, eos_id=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(\n",
    "                logits < min_val,\n",
    "                torch.tensor(float('-inf')).to(logits.device),\n",
    "                logits\n",
    "            )\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fx4AsQEiiewX",
    "outputId": "bc0fc393-9623-4f8d-e10c-e98192c73101"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you stand to work on surprise, a one of us had gone with random-\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7VGRyjJwkDDS"
   },
   "source": [
    "### saving the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "Z5sqPo1akEqW"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./data/model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RnY_yA1Hkf_-"
   },
   "source": [
    "now load it again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gukBalyPkFR2",
    "outputId": "2e33296b-8cf2-43d2-d7ec-938b137b055c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(torch.load(\"./data/model.pth\", map_location=device))\n",
    "model.eval()\n",
    "True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "4s-ZT8Jdkh3u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you stand to work on surprise, a one of us had gone with random-dication: \"Yes\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=20,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the gpt2 trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### configure and create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2-small (124M)\"\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG.update({\"context_length\": 1024}) # woo bigger context\n",
    "NEW_CONFIG.update({\"qkv_bias\": True}) # gpt2 uses bias on the qkv weight parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval()\n",
    "True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### helper function to copy weights to Parameters block checking for shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, \"\n",
    "                          \"Right: {right.shape}\"\n",
    "        )\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loader function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "\n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justinhj/projects/buildallm/.venv/lib/python3.12/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=\"124M\", models_dir=\"gpt2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device)\n",
    "True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you toward the right direction.\n",
      "\n",
      "\"You have to be careful not to make the wrong choices,\" he said.\n",
      "\n",
      "\n",
      "Output text:\n",
      " Large language models are very much in the early stages of being developed. This is partly due to the limited number of languages available, as the languages\n",
      "Output text:\n",
      " Santa Claus did not eat his parents' ashes.\n",
      "\n",
      "It is unclear how long he will be in jail or whether he will be given parole after this\n",
      "Output text:\n",
      " John and Mary got into a heated discussion about the issue of marriage equality.\n",
      "\n",
      "\"I'm glad that the Supreme Court has recognized marriage equality and that it is time\n",
      "Output text:\n",
      " On Christmas Day, Albert and Lewis were at the airport and when they arrived, they noticed there was a woman in a red shirt with a blue dress. She\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "inputs = [\n",
    "  \"Every effort moves you\",\n",
    "  \"Large language models are\",\n",
    "  \"Santa Claus did not eat his\",\n",
    "  \"John and Mary got into a heated discussion about\",\n",
    "  \"On Christmas Day, Albert and Lewis\"  \n",
    "]\n",
    "\n",
    "for input in inputs:\n",
    "    token_ids = generate(\n",
    "        model=gpt,\n",
    "        idx=text_to_token_ids(input, tokenizer).to(device),\n",
    "        max_new_tokens=25,\n",
    "        context_size=NEW_CONFIG[\"context_length\"],\n",
    "        top_k=10,\n",
    "        temperature=.8\n",
    "    )\n",
    "    print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ex 5.1: Calculate the training and validation set losses of the GPTModel with the pretrained weights from OpenAI on the â€œThe Verdictâ€ dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute to save the model state with gpt2 loaded\n",
    "# torch.save({\n",
    "#     \"model_state_dict\": model.state_dict(),\n",
    "#     \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "#     }, \n",
    "#     \"model_and_optimizer_gpt2.pth\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 0.294, Val loss 6.523\n",
      "Ep 1 (Step 000005): Train loss 0.298, Val loss 6.523\n",
      "Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed luncheon-table, when, on a later day, I had again run over from Monte Carlo; and Mrs. Gis\n",
      "Ep 2 (Step 000010): Train loss 0.312, Val loss 6.523\n",
      "Ep 2 (Step 000015): Train loss 0.287, Val loss 6.523\n",
      "Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed luncheon-table, when, on a later day, I had again run over from Monte Carlo; and Mrs. Gis\n",
      "Ep 3 (Step 000020): Train loss 0.291, Val loss 6.523\n",
      "Ep 3 (Step 000025): Train loss 0.299, Val loss 6.523\n",
      "Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed luncheon-table, when, on a later day, I had again run over from Monte Carlo; and Mrs. Gis\n",
      "Ep 4 (Step 000030): Train loss 0.316, Val loss 6.523\n",
      "Ep 4 (Step 000035): Train loss 0.295, Val loss 6.523\n",
      "Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed luncheon-table, when, on a later day, I had again run over from Monte Carlo; and Mrs. Gis\n",
      "Ep 5 (Step 000040): Train loss 0.306, Val loss 6.523\n",
      "Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed luncheon-table, when, on a later day, I had again run over from Monte Carlo; and Mrs. Gis\n",
      "Ep 6 (Step 000045): Train loss 0.303, Val loss 6.523\n",
      "Ep 6 (Step 000050): Train loss 0.294, Val loss 6.523\n",
      "Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed luncheon-table, when, on a later day, I had again run over from Monte Carlo; and Mrs. Gis\n",
      "Ep 7 (Step 000055): Train loss 0.306, Val loss 6.523\n",
      "Ep 7 (Step 000060): Train loss 0.303, Val loss 6.523\n",
      "Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed luncheon-table, when, on a later day, I had again run over from Monte Carlo; and Mrs. Gis\n",
      "Ep 8 (Step 000065): Train loss 0.286, Val loss 6.523\n",
      "Ep 8 (Step 000070): Train loss 0.313, Val loss 6.523\n",
      "Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed luncheon-table, when, on a later day, I had again run over from Monte Carlo; and Mrs. Gis\n",
      "Ep 9 (Step 000075): Train loss 0.301, Val loss 6.523\n",
      "Ep 9 (Step 000080): Train loss 0.313, Val loss 6.523\n",
      "Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed luncheon-table, when, on a later day, I had again run over from Monte Carlo; and Mrs. Gis\n",
      "Ep 10 (Step 000085): Train loss 0.286, Val loss 6.523\n",
      "Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed luncheon-table, when, on a later day, I had again run over from Monte Carlo; and Mrs. Gis\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "     gpt.parameters(),\n",
    "    lr=0.0004, weight_decay=0.1\n",
    ")\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
